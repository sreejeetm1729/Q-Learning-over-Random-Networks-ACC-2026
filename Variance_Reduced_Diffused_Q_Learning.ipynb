{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# VRDQ_error_plot.py\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, Dict, Optional\n",
        "\n",
        "\n",
        "# ============================ Utilities ============================\n",
        "\n",
        "def metropolis_mixing_matrix(adj: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Build a symmetric, doubly-stochastic mixing matrix W via Metropolis weights.\n",
        "    adj[i,j] = 1 if edge (i,j) exists (undirected), else 0. Self-loops are added automatically.\n",
        "    \"\"\"\n",
        "    N = adj.shape[0]\n",
        "    A = adj.copy().astype(float)\n",
        "    np.fill_diagonal(A, 1.0)  # ensure self-loops\n",
        "    deg = A.sum(axis=1)\n",
        "    W = np.zeros_like(A, dtype=float)\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            if i == j:\n",
        "                continue\n",
        "            if A[i, j] > 0:\n",
        "                W[i, j] = 1.0 / (1.0 + max(deg[i], deg[j]))\n",
        "        W[i, i] = 1.0 - W[i, :].sum()\n",
        "    return W  # symmetric for undirected graphs, hence doubly-stochastic\n",
        "\n",
        "\n",
        "def spectral_gap_rho(W: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Return a consensus contraction factor rho (2nd-largest eigenvalue modulus of W).\n",
        "    For connected, aperiodic graphs, the largest eigenvalue is 1.\n",
        "    \"\"\"\n",
        "    eigvals = np.linalg.eigvals(W)\n",
        "    eigvals = np.sort(np.abs(eigvals))[::-1]\n",
        "    return float(eigvals[1]) if len(eigvals) > 1 else 0.0\n",
        "\n",
        "\n",
        "def compute_alpha_K_L(\n",
        "    N: int, T: int, gamma: float, c1: float = 1.0, c2: float = 1.0, rho: Optional[float] = None\n",
        ") -> Tuple[float, int, int]:\n",
        "    r\"\"\"\n",
        "    Parameter choices:\n",
        "\n",
        "        alpha = log(NT) / ((1 - gamma) * K)\n",
        "        K     = ceil( c1 * log(NT) / (1 - gamma) )\n",
        "        L     = ceil( log( c2 * N^{3/2} * sqrt(T) / sqrt(1 - gamma) ) / log(1/rho) )\n",
        "\n",
        "    If rho is None or invalid, L defaults to 1 (caller may override).\n",
        "    \"\"\"\n",
        "    NT = max(1, N * max(1, T))\n",
        "    K = int(np.ceil(c1 * np.log(NT) / max(1e-12, (1.0 - gamma))))\n",
        "    alpha = np.log(NT) / (max(1e-12, (1.0 - gamma)) * max(1, K))\n",
        "\n",
        "    if rho is None or not (0.0 < rho < 1.0):\n",
        "        L = 1\n",
        "    else:\n",
        "        num = np.log(\n",
        "            max(1.0, c2 * (N ** 1.5) * np.sqrt(max(1, T)) / np.sqrt(max(1e-12, (1.0 - gamma))))\n",
        "        )\n",
        "        den = np.log(1.0 / rho)\n",
        "        L = int(np.ceil(num / max(1e-2, den)))\n",
        "\n",
        "    return alpha, K, L\n",
        "\n",
        "\n",
        "# ============================ Environment ============================\n",
        "\n",
        "@dataclass\n",
        "class TabularMDP:\n",
        "    P: np.ndarray  # shape [S, A, S]\n",
        "    R: np.ndarray  # shape [S, A]\n",
        "    gamma: float\n",
        "\n",
        "    @property\n",
        "    def S(self) -> int:\n",
        "        return self.P.shape[0]\n",
        "\n",
        "    @property\n",
        "    def A(self) -> int:\n",
        "        return self.P.shape[1]\n",
        "\n",
        "    def sample_next(self, s: int, a: int, rng: np.random.Generator):\n",
        "        next_s = rng.choice(self.S, p=self.P[s, a])\n",
        "        r = self.R[s, a]\n",
        "        return int(next_s), float(r)\n",
        "\n",
        "\n",
        "# ============================ VRDQ Core ============================\n",
        "\n",
        "def empirical_transition(\n",
        "    N: int, S: int, A: int, H: int, mdp: TabularMDP, rng: np.random.Generator\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Return empirical transition tensors P_hat with shape [N, S, A, S].\n",
        "    For each agent and each (s,a), collect H samples and estimate next-state dist.\n",
        "    \"\"\"\n",
        "    P_hat = np.zeros((N, S, A, S), dtype=float)\n",
        "    for i in range(N):\n",
        "        for s in range(S):\n",
        "            for a in range(A):\n",
        "                counts = np.zeros(S, dtype=float)\n",
        "                for _ in range(H):\n",
        "                    ns = rng.choice(S, p=mdp.P[s, a])\n",
        "                    counts[ns] += 1.0\n",
        "                if counts.sum() > 0:\n",
        "                    P_hat[i, s, a] = counts / counts.sum()\n",
        "                else:\n",
        "                    P_hat[i, s, a] = np.ones(S) / S\n",
        "    return P_hat\n",
        "\n",
        "\n",
        "def q_update_pre_diffusion(\n",
        "    Q_i: np.ndarray, P_hat_i: np.ndarray, R: np.ndarray, gamma: float, alpha: float\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Compute d^{(0)} for one agent across all (s,a): shape [S, A].\n",
        "    d^{(0)}(s,a) = alpha * ( R(s,a) + gamma * E_{s'~P_hat}[ max_{a'} Q(s',a') ] - Q(s,a) )\n",
        "    \"\"\"\n",
        "    S, A = Q_i.shape\n",
        "    d0 = np.zeros_like(Q_i)\n",
        "    Q_max = Q_i.max(axis=1)  # shape [S]\n",
        "    for s in range(S):\n",
        "        for a in range(A):\n",
        "            v_next = float(P_hat_i[s, a] @ Q_max)\n",
        "            td = R[s, a] + gamma * v_next - Q_i[s, a]\n",
        "            d0[s, a] = alpha * td\n",
        "    return d0\n",
        "\n",
        "\n",
        "def diffuse_deltas_over_agents(d0_stack: np.ndarray, W: np.ndarray, L: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Diffuse per-(s,a) deltas across agents.\n",
        "    d0_stack shape: [N, S, A]. We apply W^L to the agent dimension for each (s,a).\n",
        "    \"\"\"\n",
        "    if L <= 0:\n",
        "        return d0_stack.copy()\n",
        "    WL = np.linalg.matrix_power(W, L)\n",
        "    N, S, A = d0_stack.shape\n",
        "    dL = np.zeros_like(d0_stack)\n",
        "    for s in range(S):\n",
        "        for a in range(A):\n",
        "            dL[:, s, a] = WL @ d0_stack[:, s, a]\n",
        "    return dL\n",
        "\n",
        "\n",
        "def vrdq_train(\n",
        "    mdp: TabularMDP,\n",
        "    N: int,\n",
        "    H: int,\n",
        "    K: int,\n",
        "    L: int,\n",
        "    alpha: float,\n",
        "    W: np.ndarray,\n",
        "    seed: int = 0\n",
        ") -> Dict[str, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Run VRDQ for K epochs. Returns dict with final Qs and history.\n",
        "    Q is maintained per agent with shape [N, S, A].\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    S, A = mdp.S, mdp.A\n",
        "    Q = np.zeros((N, S, A), dtype=float)\n",
        "\n",
        "    Q_hist = []  # average Q per epoch\n",
        "    for _ in range(K):\n",
        "        P_hat = empirical_transition(N, S, A, H, mdp, rng)   # [N,S,A,S]\n",
        "        d0 = np.zeros((N, S, A), dtype=float)\n",
        "        for i in range(N):\n",
        "            d0[i] = q_update_pre_diffusion(Q[i], P_hat[i], mdp.R, mdp.gamma, alpha)\n",
        "        dL = diffuse_deltas_over_agents(d0, W, L)            # [N,S,A]\n",
        "        Q += dL\n",
        "        Q_hist.append(Q.mean(axis=0))\n",
        "\n",
        "    return {\n",
        "        \"Q_agents\": Q,                 # [N,S,A]\n",
        "        \"Q_bar\": Q.mean(axis=0),       # [S,A]\n",
        "        \"Q_hist\": np.array(Q_hist),    # [K,S,A]\n",
        "        \"W\": W,\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================ Helpers ============================\n",
        "\n",
        "def random_tabular_mdp(S: int, A: int, gamma: float, rng: np.random.Generator) -> TabularMDP:\n",
        "    P = rng.random((S, A, S))\n",
        "    P /= P.sum(axis=2, keepdims=True)\n",
        "    R = rng.random((S, A))  # rewards in [0,1]\n",
        "    return TabularMDP(P=P, R=R, gamma=gamma)\n",
        "\n",
        "\n",
        "def ring_graph_adj(N: int) -> np.ndarray:\n",
        "    adj = np.zeros((N, N), dtype=int)\n",
        "    for i in range(N):\n",
        "        adj[i, i] = 1\n",
        "        adj[i, (i - 1) % N] = 1\n",
        "        adj[i, (i + 1) % N] = 1\n",
        "    return adj\n",
        "\n",
        "\n",
        "def value_iteration(mdp: TabularMDP, tol: float = 1e-10, max_iter: int = 10000):\n",
        "    \"\"\"\n",
        "    Compute optimal Q* (and V*) for a tabular MDP via value iteration.\n",
        "    \"\"\"\n",
        "    S, A, gamma = mdp.S, mdp.A, mdp.gamma\n",
        "    V = np.zeros(S, dtype=float)\n",
        "    for _ in range(max_iter):\n",
        "        Q = np.zeros((S, A), dtype=float)\n",
        "        for s in range(S):\n",
        "            for a in range(A):\n",
        "                Q[s, a] = mdp.R[s, a] + gamma * float(mdp.P[s, a] @ V)\n",
        "        V_new = Q.max(axis=1)\n",
        "        if np.max(np.abs(V_new - V)) < tol:\n",
        "            V = V_new\n",
        "            break\n",
        "        V = V_new\n",
        "    Q_star = np.zeros((S, A), dtype=float)\n",
        "    for s in range(S):\n",
        "        for a in range(A):\n",
        "            Q_star[s, a] = mdp.R[s, a] + gamma * float(mdp.P[s, a] @ V)\n",
        "    return Q_star, V\n",
        "\n",
        "\n",
        "# ============================ Main: Train + Plot ============================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    rng = np.random.default_rng(7)\n",
        "\n",
        "    # Problem sizes\n",
        "    S, A = 10, 5\n",
        "    N = 5            # number of agents\n",
        "    gamma = 0.9\n",
        "    T = 100_000      # used only to set (alpha, K, L)\n",
        "    c1, c2 = 1.0, 1.0\n",
        "    #H = 5            # samples per (s,a) per agent per epoch\n",
        "\n",
        "    # Build MDP and network\n",
        "    mdp = random_tabular_mdp(S, A, gamma, rng)\n",
        "    adj = ring_graph_adj(N)\n",
        "    W = metropolis_mixing_matrix(adj)\n",
        "    rho = spectral_gap_rho(W)\n",
        "\n",
        "    # Choose (alpha, K, L)\n",
        "    alpha, K, L = compute_alpha_K_L(N=N, T=T, gamma=gamma, c1=c1, c2=c2, rho=rho)\n",
        "    H=int(T/K)\n",
        "    print(f\"Using: alpha={alpha:.4g}, K={K}, L={L}, rho={rho:.4f}, N={N}, S={S}, A={A}, H={H}\")\n",
        "\n",
        "    # Train VRDQ\n",
        "    out = vrdq_train(mdp, N=N, H=H, K=K, L=L, alpha=alpha, W=W, seed=123)\n",
        "    Q_hist = out[\"Q_hist\"]              # [K,S,A]\n",
        "    Q_bar_final = out[\"Q_bar\"]          # [S,A]\n",
        "\n",
        "    # Compute Q* and ℓ∞ error per epoch\n",
        "    Q_star, _ = value_iteration(mdp)\n",
        "    E = np.zeros(Q_hist.shape[0], dtype=float)\n",
        "    for k in range(Q_hist.shape[0]):\n",
        "        E[k] = np.max(np.abs(Q_hist[k] - Q_star))\n",
        "\n",
        "    # Save artifacts\n",
        "    np.save('vrdq_error_linfty_N5.npy', E)\n",
        "    np.save('vrdq_Qstar.npy', Q_star)\n",
        "    np.save('vrdq_Qhist.npy', Q_hist)\n",
        "\n",
        "    # Plot (single plot; matplotlib only; no specified colors)\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    plt.semilogy(range(1, len(E) + 1), E, linewidth=5)\n",
        "    plt.xlabel('$\\mathbf{K}$', fontsize=40, fontweight='bold')\n",
        "    plt.ylabel(r'$\\mathbf{E_K}$', fontsize=40, fontweight='bold')\n",
        "    plt.title('$\\mathbf{Variance \\quad Reduced \\quad Diffused \\quad Q-Learning}\\quad (VRDQ)$')\n",
        "    plt.grid(True, which='both', linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('vrdq_error_plot_N5.png', dpi=1200)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "u7blIr5gQbhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VRDQ_error_plot.py\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, Dict, Optional\n",
        "\n",
        "\n",
        "# ============================ Utilities ============================\n",
        "\n",
        "def metropolis_mixing_matrix(adj: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Build a symmetric, doubly-stochastic mixing matrix W via Metropolis weights.\n",
        "    adj[i,j] = 1 if edge (i,j) exists (undirected), else 0. Self-loops are added automatically.\n",
        "    \"\"\"\n",
        "    N = adj.shape[0]\n",
        "    A = adj.copy().astype(float)\n",
        "    np.fill_diagonal(A, 1.0)  # ensure self-loops\n",
        "    deg = A.sum(axis=1)\n",
        "    W = np.zeros_like(A, dtype=float)\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            if i == j:\n",
        "                continue\n",
        "            if A[i, j] > 0:\n",
        "                W[i, j] = 1.0 / (1.0 + max(deg[i], deg[j]))\n",
        "        W[i, i] = 1.0 - W[i, :].sum()\n",
        "    return W  # symmetric for undirected graphs, hence doubly-stochastic\n",
        "\n",
        "\n",
        "def spectral_gap_rho(W: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Return a consensus contraction factor rho (2nd-largest eigenvalue modulus of W).\n",
        "    For connected, aperiodic graphs, the largest eigenvalue is 1.\n",
        "    \"\"\"\n",
        "    eigvals = np.linalg.eigvals(W)\n",
        "    eigvals = np.sort(np.abs(eigvals))[::-1]\n",
        "    return float(eigvals[1]) if len(eigvals) > 1 else 0.0\n",
        "\n",
        "\n",
        "def compute_alpha_K_L(\n",
        "    N: int, T: int, gamma: float, c1: float = 1.0, c2: float = 1.0, rho: Optional[float] = None\n",
        ") -> Tuple[float, int, int]:\n",
        "    r\"\"\"\n",
        "    Parameter choices:\n",
        "\n",
        "        alpha = log(NT) / ((1 - gamma) * K)\n",
        "        K     = ceil( c1 * log(NT) / (1 - gamma) )\n",
        "        L     = ceil( log( c2 * N^{3/2} * sqrt(T) / sqrt(1 - gamma) ) / log(1/rho) )\n",
        "\n",
        "    If rho is None or invalid, L defaults to 1 (caller may override).\n",
        "    \"\"\"\n",
        "    NT = max(1, N * max(1, T))\n",
        "    K = int(np.ceil(c1 * np.log(NT) / max(1e-12, (1.0 - gamma))))\n",
        "    alpha = np.log(NT) / (max(1e-12, (1.0 - gamma)) * max(1, K))\n",
        "\n",
        "    if rho is None or not (0.0 < rho < 1.0):\n",
        "        L = 1\n",
        "    else:\n",
        "        num = np.log(\n",
        "            max(1.0, c2 * (N ** 1.5) * np.sqrt(max(1, T)) / np.sqrt(max(1e-12, (1.0 - gamma))))\n",
        "        )\n",
        "        den = np.log(1.0 / rho)\n",
        "        L = int(np.ceil(num / max(1e-2, den)))\n",
        "\n",
        "    return alpha, K, L\n",
        "\n",
        "\n",
        "# ============================ Environment ============================\n",
        "\n",
        "@dataclass\n",
        "class TabularMDP:\n",
        "    P: np.ndarray  # shape [S, A, S]\n",
        "    R: np.ndarray  # shape [S, A]\n",
        "    gamma: float\n",
        "\n",
        "    @property\n",
        "    def S(self) -> int:\n",
        "        return self.P.shape[0]\n",
        "\n",
        "    @property\n",
        "    def A(self) -> int:\n",
        "        return self.P.shape[1]\n",
        "\n",
        "    def sample_next(self, s: int, a: int, rng: np.random.Generator):\n",
        "        next_s = rng.choice(self.S, p=self.P[s, a])\n",
        "        r = self.R[s, a]\n",
        "        return int(next_s), float(r)\n",
        "\n",
        "\n",
        "# ============================ VRDQ Core ============================\n",
        "\n",
        "def empirical_transition(\n",
        "    N: int, S: int, A: int, H: int, mdp: TabularMDP, rng: np.random.Generator\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Return empirical transition tensors P_hat with shape [N, S, A, S].\n",
        "    For each agent and each (s,a), collect H samples and estimate next-state dist.\n",
        "    \"\"\"\n",
        "    P_hat = np.zeros((N, S, A, S), dtype=float)\n",
        "    for i in range(N):\n",
        "        for s in range(S):\n",
        "            for a in range(A):\n",
        "                counts = np.zeros(S, dtype=float)\n",
        "                for _ in range(H):\n",
        "                    ns = rng.choice(S, p=mdp.P[s, a])\n",
        "                    counts[ns] += 1.0\n",
        "                if counts.sum() > 0:\n",
        "                    P_hat[i, s, a] = counts / counts.sum()\n",
        "                else:\n",
        "                    P_hat[i, s, a] = np.ones(S) / S\n",
        "    return P_hat\n",
        "\n",
        "\n",
        "def q_update_pre_diffusion(\n",
        "    Q_i: np.ndarray, P_hat_i: np.ndarray, R: np.ndarray, gamma: float, alpha: float\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Compute d^{(0)} for one agent across all (s,a): shape [S, A].\n",
        "    d^{(0)}(s,a) = alpha * ( R(s,a) + gamma * E_{s'~P_hat}[ max_{a'} Q(s',a') ] - Q(s,a) )\n",
        "    \"\"\"\n",
        "    S, A = Q_i.shape\n",
        "    d0 = np.zeros_like(Q_i)\n",
        "    Q_max = Q_i.max(axis=1)  # shape [S]\n",
        "    for s in range(S):\n",
        "        for a in range(A):\n",
        "            v_next = float(P_hat_i[s, a] @ Q_max)\n",
        "            td = R[s, a] + gamma * v_next - Q_i[s, a]\n",
        "            d0[s, a] = alpha * td\n",
        "    return d0\n",
        "\n",
        "\n",
        "def diffuse_deltas_over_agents(d0_stack: np.ndarray, W: np.ndarray, L: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Diffuse per-(s,a) deltas across agents.\n",
        "    d0_stack shape: [N, S, A]. We apply W^L to the agent dimension for each (s,a).\n",
        "    \"\"\"\n",
        "    if L <= 0:\n",
        "        return d0_stack.copy()\n",
        "    WL = np.linalg.matrix_power(W, L)\n",
        "    N, S, A = d0_stack.shape\n",
        "    dL = np.zeros_like(d0_stack)\n",
        "    for s in range(S):\n",
        "        for a in range(A):\n",
        "            dL[:, s, a] = WL @ d0_stack[:, s, a]\n",
        "    return dL\n",
        "\n",
        "\n",
        "def vrdq_train(\n",
        "    mdp: TabularMDP,\n",
        "    N: int,\n",
        "    H: int,\n",
        "    K: int,\n",
        "    L: int,\n",
        "    alpha: float,\n",
        "    W: np.ndarray,\n",
        "    seed: int = 0\n",
        ") -> Dict[str, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Run VRDQ for K epochs. Returns dict with final Qs and history.\n",
        "    Q is maintained per agent with shape [N, S, A].\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    S, A = mdp.S, mdp.A\n",
        "    Q = np.zeros((N, S, A), dtype=float)\n",
        "\n",
        "    Q_hist = []  # average Q per epoch\n",
        "    for _ in range(K):\n",
        "        P_hat = empirical_transition(N, S, A, H, mdp, rng)   # [N,S,A,S]\n",
        "        d0 = np.zeros((N, S, A), dtype=float)\n",
        "        for i in range(N):\n",
        "            d0[i] = q_update_pre_diffusion(Q[i], P_hat[i], mdp.R, mdp.gamma, alpha)\n",
        "        dL = diffuse_deltas_over_agents(d0, W, L)            # [N,S,A]\n",
        "        Q += dL\n",
        "        Q_hist.append(Q.mean(axis=0))\n",
        "\n",
        "    return {\n",
        "        \"Q_agents\": Q,                 # [N,S,A]\n",
        "        \"Q_bar\": Q.mean(axis=0),       # [S,A]\n",
        "        \"Q_hist\": np.array(Q_hist),    # [K,S,A]\n",
        "        \"W\": W,\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================ Helpers ============================\n",
        "\n",
        "def random_tabular_mdp(S: int, A: int, gamma: float, rng: np.random.Generator) -> TabularMDP:\n",
        "    P = rng.random((S, A, S))\n",
        "    P /= P.sum(axis=2, keepdims=True)\n",
        "    R = rng.random((S, A))  # rewards in [0,1]\n",
        "    return TabularMDP(P=P, R=R, gamma=gamma)\n",
        "\n",
        "\n",
        "def ring_graph_adj(N: int) -> np.ndarray:\n",
        "    adj = np.zeros((N, N), dtype=int)\n",
        "    for i in range(N):\n",
        "        adj[i, i] = 1\n",
        "        adj[i, (i - 1) % N] = 1\n",
        "        adj[i, (i + 1) % N] = 1\n",
        "    return adj\n",
        "\n",
        "\n",
        "def value_iteration(mdp: TabularMDP, tol: float = 1e-10, max_iter: int = 10000):\n",
        "    \"\"\"\n",
        "    Compute optimal Q* (and V*) for a tabular MDP via value iteration.\n",
        "    \"\"\"\n",
        "    S, A, gamma = mdp.S, mdp.A, mdp.gamma\n",
        "    V = np.zeros(S, dtype=float)\n",
        "    for _ in range(max_iter):\n",
        "        Q = np.zeros((S, A), dtype=float)\n",
        "        for s in range(S):\n",
        "            for a in range(A):\n",
        "                Q[s, a] = mdp.R[s, a] + gamma * float(mdp.P[s, a] @ V)\n",
        "        V_new = Q.max(axis=1)\n",
        "        if np.max(np.abs(V_new - V)) < tol:\n",
        "            V = V_new\n",
        "            break\n",
        "        V = V_new\n",
        "    Q_star = np.zeros((S, A), dtype=float)\n",
        "    for s in range(S):\n",
        "        for a in range(A):\n",
        "            Q_star[s, a] = mdp.R[s, a] + gamma * float(mdp.P[s, a] @ V)\n",
        "    return Q_star, V\n",
        "\n",
        "\n",
        "# ============================ Main: Train + Plot ============================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    rng = np.random.default_rng(7)\n",
        "\n",
        "    # Problem sizes\n",
        "    S, A = 10, 5\n",
        "    N = 10            # number of agents\n",
        "    gamma = 0.9\n",
        "    T = 100_000      # used only to set (alpha, K, L)\n",
        "    c1, c2 = 1.0, 1.0\n",
        "    #H = 5            # samples per (s,a) per agent per epoch\n",
        "\n",
        "    # Build MDP and network\n",
        "    mdp = random_tabular_mdp(S, A, gamma, rng)\n",
        "    adj = ring_graph_adj(N)\n",
        "    W = metropolis_mixing_matrix(adj)\n",
        "    rho = spectral_gap_rho(W)\n",
        "\n",
        "    # Choose (alpha, K, L)\n",
        "    alpha, K, L = compute_alpha_K_L(N=N, T=T, gamma=gamma, c1=c1, c2=c2, rho=rho)\n",
        "    H=int(T/K)\n",
        "    print(f\"Using: alpha={alpha:.4g}, K={K}, L={L}, rho={rho:.4f}, N={N}, S={S}, A={A}, H={H}\")\n",
        "\n",
        "    # Train VRDQ\n",
        "    out = vrdq_train(mdp, N=N, H=H, K=K, L=L, alpha=alpha, W=W, seed=123)\n",
        "    Q_hist = out[\"Q_hist\"]              # [K,S,A]\n",
        "    Q_bar_final = out[\"Q_bar\"]          # [S,A]\n",
        "\n",
        "    # Compute Q* and ℓ∞ error per epoch\n",
        "    Q_star, _ = value_iteration(mdp)\n",
        "    E = np.zeros(Q_hist.shape[0], dtype=float)\n",
        "    for k in range(Q_hist.shape[0]):\n",
        "        E[k] = np.max(np.abs(Q_hist[k] - Q_star))\n",
        "\n",
        "    # Save artifacts\n",
        "    np.save('vrdq_error_linfty_N10.npy', E)\n",
        "    np.save('vrdq_Qstar.npy', Q_star)\n",
        "    np.save('vrdq_Qhist.npy', Q_hist)\n",
        "\n",
        "    # Plot (single plot; matplotlib only; no specified colors)\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    plt.semilogy(range(1, len(E) + 1), E, linewidth=5)\n",
        "    plt.xlabel('$\\mathbf{K}$', fontsize=40, fontweight='bold')\n",
        "    plt.ylabel(r'$\\mathbf{E_K}$', fontsize=40, fontweight='bold')\n",
        "    plt.title('$\\mathbf{Variance \\quad Reduced \\quad Diffused \\quad Q-Learning}\\quad (VRDQ)$')\n",
        "    plt.grid(True, which='both', linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('vrdq_error_plot_N10.png', dpi=1200)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "_Nu8PN68bUnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VRDQ_error_plot.py\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, Dict, Optional\n",
        "\n",
        "\n",
        "# ============================ Utilities ============================\n",
        "\n",
        "def metropolis_mixing_matrix(adj: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Build a symmetric, doubly-stochastic mixing matrix W via Metropolis weights.\n",
        "    adj[i,j] = 1 if edge (i,j) exists (undirected), else 0. Self-loops are added automatically.\n",
        "    \"\"\"\n",
        "    N = adj.shape[0]\n",
        "    A = adj.copy().astype(float)\n",
        "    np.fill_diagonal(A, 1.0)  # ensure self-loops\n",
        "    deg = A.sum(axis=1)\n",
        "    W = np.zeros_like(A, dtype=float)\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            if i == j:\n",
        "                continue\n",
        "            if A[i, j] > 0:\n",
        "                W[i, j] = 1.0 / (1.0 + max(deg[i], deg[j]))\n",
        "        W[i, i] = 1.0 - W[i, :].sum()\n",
        "    return W  # symmetric for undirected graphs, hence doubly-stochastic\n",
        "\n",
        "\n",
        "def spectral_gap_rho(W: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Return a consensus contraction factor rho (2nd-largest eigenvalue modulus of W).\n",
        "    For connected, aperiodic graphs, the largest eigenvalue is 1.\n",
        "    \"\"\"\n",
        "    eigvals = np.linalg.eigvals(W)\n",
        "    eigvals = np.sort(np.abs(eigvals))[::-1]\n",
        "    return float(eigvals[1]) if len(eigvals) > 1 else 0.0\n",
        "\n",
        "\n",
        "def compute_alpha_K_L(\n",
        "    N: int, T: int, gamma: float, c1: float = 1.0, c2: float = 1.0, rho: Optional[float] = None\n",
        ") -> Tuple[float, int, int]:\n",
        "    r\"\"\"\n",
        "    Parameter choices:\n",
        "\n",
        "        alpha = log(NT) / ((1 - gamma) * K)\n",
        "        K     = ceil( c1 * log(NT) / (1 - gamma) )\n",
        "        L     = ceil( log( c2 * N^{3/2} * sqrt(T) / sqrt(1 - gamma) ) / log(1/rho) )\n",
        "\n",
        "    If rho is None or invalid, L defaults to 1 (caller may override).\n",
        "    \"\"\"\n",
        "    NT = max(1, N * max(1, T))\n",
        "    K = int(np.ceil(c1 * np.log(NT) / max(1e-12, (1.0 - gamma))))\n",
        "    alpha = np.log(NT) / (max(1e-12, (1.0 - gamma)) * max(1, K))\n",
        "\n",
        "    if rho is None or not (0.0 < rho < 1.0):\n",
        "        L = 1\n",
        "    else:\n",
        "        num = np.log(\n",
        "            max(1.0, c2 * (N ** 1.5) * np.sqrt(max(1, T)) / np.sqrt(max(1e-12, (1.0 - gamma))))\n",
        "        )\n",
        "        den = np.log(1.0 / rho)\n",
        "        L = int(np.ceil(num / max(1e-2, den)))\n",
        "\n",
        "    return alpha, K, L\n",
        "\n",
        "\n",
        "# ============================ Environment ============================\n",
        "\n",
        "@dataclass\n",
        "class TabularMDP:\n",
        "    P: np.ndarray  # shape [S, A, S]\n",
        "    R: np.ndarray  # shape [S, A]\n",
        "    gamma: float\n",
        "\n",
        "    @property\n",
        "    def S(self) -> int:\n",
        "        return self.P.shape[0]\n",
        "\n",
        "    @property\n",
        "    def A(self) -> int:\n",
        "        return self.P.shape[1]\n",
        "\n",
        "    def sample_next(self, s: int, a: int, rng: np.random.Generator):\n",
        "        next_s = rng.choice(self.S, p=self.P[s, a])\n",
        "        r = self.R[s, a]\n",
        "        return int(next_s), float(r)\n",
        "\n",
        "\n",
        "# ============================ VRDQ Core ============================\n",
        "\n",
        "def empirical_transition(\n",
        "    N: int, S: int, A: int, H: int, mdp: TabularMDP, rng: np.random.Generator\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Return empirical transition tensors P_hat with shape [N, S, A, S].\n",
        "    For each agent and each (s,a), collect H samples and estimate next-state dist.\n",
        "    \"\"\"\n",
        "    P_hat = np.zeros((N, S, A, S), dtype=float)\n",
        "    for i in range(N):\n",
        "        for s in range(S):\n",
        "            for a in range(A):\n",
        "                counts = np.zeros(S, dtype=float)\n",
        "                for _ in range(H):\n",
        "                    ns = rng.choice(S, p=mdp.P[s, a])\n",
        "                    counts[ns] += 1.0\n",
        "                if counts.sum() > 0:\n",
        "                    P_hat[i, s, a] = counts / counts.sum()\n",
        "                else:\n",
        "                    P_hat[i, s, a] = np.ones(S) / S\n",
        "    return P_hat\n",
        "\n",
        "\n",
        "def q_update_pre_diffusion(\n",
        "    Q_i: np.ndarray, P_hat_i: np.ndarray, R: np.ndarray, gamma: float, alpha: float\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Compute d^{(0)} for one agent across all (s,a): shape [S, A].\n",
        "    d^{(0)}(s,a) = alpha * ( R(s,a) + gamma * E_{s'~P_hat}[ max_{a'} Q(s',a') ] - Q(s,a) )\n",
        "    \"\"\"\n",
        "    S, A = Q_i.shape\n",
        "    d0 = np.zeros_like(Q_i)\n",
        "    Q_max = Q_i.max(axis=1)  # shape [S]\n",
        "    for s in range(S):\n",
        "        for a in range(A):\n",
        "            v_next = float(P_hat_i[s, a] @ Q_max)\n",
        "            td = R[s, a] + gamma * v_next - Q_i[s, a]\n",
        "            d0[s, a] = alpha * td\n",
        "    return d0\n",
        "\n",
        "\n",
        "def diffuse_deltas_over_agents(d0_stack: np.ndarray, W: np.ndarray, L: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Diffuse per-(s,a) deltas across agents.\n",
        "    d0_stack shape: [N, S, A]. We apply W^L to the agent dimension for each (s,a).\n",
        "    \"\"\"\n",
        "    if L <= 0:\n",
        "        return d0_stack.copy()\n",
        "    WL = np.linalg.matrix_power(W, L)\n",
        "    N, S, A = d0_stack.shape\n",
        "    dL = np.zeros_like(d0_stack)\n",
        "    for s in range(S):\n",
        "        for a in range(A):\n",
        "            dL[:, s, a] = WL @ d0_stack[:, s, a]\n",
        "    return dL\n",
        "\n",
        "\n",
        "def vrdq_train(\n",
        "    mdp: TabularMDP,\n",
        "    N: int,\n",
        "    H: int,\n",
        "    K: int,\n",
        "    L: int,\n",
        "    alpha: float,\n",
        "    W: np.ndarray,\n",
        "    seed: int = 0\n",
        ") -> Dict[str, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Run VRDQ for K epochs. Returns dict with final Qs and history.\n",
        "    Q is maintained per agent with shape [N, S, A].\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    S, A = mdp.S, mdp.A\n",
        "    Q = np.zeros((N, S, A), dtype=float)\n",
        "\n",
        "    Q_hist = []  # average Q per epoch\n",
        "    for _ in range(K):\n",
        "        P_hat = empirical_transition(N, S, A, H, mdp, rng)   # [N,S,A,S]\n",
        "        d0 = np.zeros((N, S, A), dtype=float)\n",
        "        for i in range(N):\n",
        "            d0[i] = q_update_pre_diffusion(Q[i], P_hat[i], mdp.R, mdp.gamma, alpha)\n",
        "        dL = diffuse_deltas_over_agents(d0, W, L)            # [N,S,A]\n",
        "        Q += dL\n",
        "        Q_hist.append(Q.mean(axis=0))\n",
        "\n",
        "    return {\n",
        "        \"Q_agents\": Q,                 # [N,S,A]\n",
        "        \"Q_bar\": Q.mean(axis=0),       # [S,A]\n",
        "        \"Q_hist\": np.array(Q_hist),    # [K,S,A]\n",
        "        \"W\": W,\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================ Helpers ============================\n",
        "\n",
        "def random_tabular_mdp(S: int, A: int, gamma: float, rng: np.random.Generator) -> TabularMDP:\n",
        "    P = rng.random((S, A, S))\n",
        "    P /= P.sum(axis=2, keepdims=True)\n",
        "    R = rng.random((S, A))  # rewards in [0,1]\n",
        "    return TabularMDP(P=P, R=R, gamma=gamma)\n",
        "\n",
        "\n",
        "def ring_graph_adj(N: int) -> np.ndarray:\n",
        "    adj = np.zeros((N, N), dtype=int)\n",
        "    for i in range(N):\n",
        "        adj[i, i] = 1\n",
        "        adj[i, (i - 1) % N] = 1\n",
        "        adj[i, (i + 1) % N] = 1\n",
        "    return adj\n",
        "\n",
        "\n",
        "def value_iteration(mdp: TabularMDP, tol: float = 1e-10, max_iter: int = 10000):\n",
        "    \"\"\"\n",
        "    Compute optimal Q* (and V*) for a tabular MDP via value iteration.\n",
        "    \"\"\"\n",
        "    S, A, gamma = mdp.S, mdp.A, mdp.gamma\n",
        "    V = np.zeros(S, dtype=float)\n",
        "    for _ in range(max_iter):\n",
        "        Q = np.zeros((S, A), dtype=float)\n",
        "        for s in range(S):\n",
        "            for a in range(A):\n",
        "                Q[s, a] = mdp.R[s, a] + gamma * float(mdp.P[s, a] @ V)\n",
        "        V_new = Q.max(axis=1)\n",
        "        if np.max(np.abs(V_new - V)) < tol:\n",
        "            V = V_new\n",
        "            break\n",
        "        V = V_new\n",
        "    Q_star = np.zeros((S, A), dtype=float)\n",
        "    for s in range(S):\n",
        "        for a in range(A):\n",
        "            Q_star[s, a] = mdp.R[s, a] + gamma * float(mdp.P[s, a] @ V)\n",
        "    return Q_star, V\n",
        "\n",
        "\n",
        "# ============================ Main: Train + Plot ============================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    rng = np.random.default_rng(7)\n",
        "\n",
        "    # Problem sizes\n",
        "    S, A = 10, 5\n",
        "    N = 100            # number of agents\n",
        "    gamma = 0.9\n",
        "    T = 100_000      # used only to set (alpha, K, L)\n",
        "    c1, c2 = 1.0, 1.0\n",
        "    #H = 5            # samples per (s,a) per agent per epoch\n",
        "\n",
        "    # Build MDP and network\n",
        "    mdp = random_tabular_mdp(S, A, gamma, rng)\n",
        "    adj = ring_graph_adj(N)\n",
        "    W = metropolis_mixing_matrix(adj)\n",
        "    rho = spectral_gap_rho(W)\n",
        "\n",
        "    # Choose (alpha, K, L)\n",
        "    alpha, K, L = compute_alpha_K_L(N=N, T=T, gamma=gamma, c1=c1, c2=c2, rho=rho)\n",
        "    H=int(T/K)\n",
        "    print(f\"Using: alpha={alpha:.4g}, K={K}, L={L}, rho={rho:.4f}, N={N}, S={S}, A={A}, H={H}\")\n",
        "\n",
        "    # Train VRDQ\n",
        "    out = vrdq_train(mdp, N=N, H=H, K=K, L=L, alpha=alpha, W=W, seed=123)\n",
        "    Q_hist = out[\"Q_hist\"]              # [K,S,A]\n",
        "    Q_bar_final = out[\"Q_bar\"]          # [S,A]\n",
        "\n",
        "    # Compute Q* and ℓ∞ error per epoch\n",
        "    Q_star, _ = value_iteration(mdp)\n",
        "    E = np.zeros(Q_hist.shape[0], dtype=float)\n",
        "    for k in range(Q_hist.shape[0]):\n",
        "        E[k] = np.max(np.abs(Q_hist[k] - Q_star))\n",
        "\n",
        "    # Save artifacts\n",
        "    np.save('vrdq_error_linfty_N100.npy', E)\n",
        "    np.save('vrdq_Qstar.npy', Q_star)\n",
        "    np.save('vrdq_Qhist.npy', Q_hist)\n",
        "\n",
        "    # Plot (single plot; matplotlib only; no specified colors)\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    plt.semilogy(range(1, len(E) + 1), E, linewidth=5)\n",
        "    plt.xlabel('$\\mathbf{K}$', fontsize=40, fontweight='bold')\n",
        "    plt.ylabel(r'$\\mathbf{E_K}$', fontsize=40, fontweight='bold')\n",
        "    plt.title('$\\mathbf{Variance \\quad Reduced \\quad Diffused \\quad Q-Learning}\\quad (VRDQ)$')\n",
        "    plt.grid(True, which='both', linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('vrdq_error_plot_N100.png', dpi=1200)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "wXejlVPCbgdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "e5   = np.load(\"vrdq_error_linfty_N5.npy\", allow_pickle=True).squeeze()\n",
        "e10  = np.load(\"vrdq_error_linfty_N10.npy\", allow_pickle=True).squeeze()\n",
        "e100 = np.load(\"vrdq_error_linfty_N100.npy\", allow_pickle=True).squeeze()\n",
        "\n",
        "T = min(len(e5), len(e10), len(e100))\n",
        "e5, e10, e100 = e5[:T], e10[:T], e100[:T]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.semilogy(e5,   label=\"N=5\",   linewidth=2)\n",
        "plt.semilogy(e10,  label=\"N=10\",  linewidth=2.5)\n",
        "plt.semilogy(e100, label=\"N=100\", linewidth=3)\n",
        "\n",
        "plt.xlabel(r'$\\mathbf{K}$', fontsize=40, fontweight='bold')\n",
        "plt.ylabel(r'$\\mathbf{E_K}$', fontsize=40, fontweight='bold')\n",
        "plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "# only call legend ONCE\n",
        "plt.legend(title=r'$\\mathbf{Agents}$', fontsize=20, title_fontsize=20, loc='best')\n",
        "\n",
        "plt.xticks(fontsize=25, fontweight='bold')\n",
        "plt.yticks(fontsize=25, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YGO08MpJgxxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VRDQ_compare_three_graphs_with_consensus.py\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, Dict, Optional\n",
        "\n",
        "# ---------- Deterministic graphs & mixing ----------\n",
        "\n",
        "def adj_ring(N: int) -> np.ndarray:\n",
        "    adj = np.zeros((N, N), dtype=int)\n",
        "    for i in range(N):\n",
        "        adj[i, (i - 1) % N] = 1\n",
        "        adj[i, (i + 1) % N] = 1\n",
        "    return adj\n",
        "\n",
        "def adj_complete(N: int) -> np.ndarray:\n",
        "    return np.ones((N, N), dtype=int) - np.eye(N, dtype=int)\n",
        "\n",
        "def adj_star(N: int) -> np.ndarray:\n",
        "    adj = np.zeros((N, N), dtype=int)\n",
        "    for j in range(1, N):\n",
        "        adj[0, j] = 1\n",
        "        adj[j, 0] = 1\n",
        "    return adj\n",
        "\n",
        "def metropolis_mixing_matrix(adj: np.ndarray) -> np.ndarray:\n",
        "    N = adj.shape[0]\n",
        "    A = adj.astype(float).copy()\n",
        "    np.fill_diagonal(A, 1.0)           # add self-loops deterministically\n",
        "    deg = A.sum(axis=1)                # includes self-loop\n",
        "    W = np.zeros_like(A, dtype=float)\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            if i == j: continue\n",
        "            if A[i, j] > 0:\n",
        "                W[i, j] = 1.0 / (1.0 + max(deg[i], deg[j]))\n",
        "        W[i, i] = 1.0 - W[i, :].sum()\n",
        "    return W                            # symmetric => doubly-stochastic\n",
        "\n",
        "def spectral_gap_rho(W: np.ndarray) -> float:\n",
        "    eig = np.linalg.eigvals(W)\n",
        "    eig = np.sort(np.abs(eig))[::-1]\n",
        "    return float(eig[1]) if len(eig) > 1 else 0.0\n",
        "\n",
        "# ---------- Hyperparameters ----------\n",
        "\n",
        "def compute_alpha_K_L(\n",
        "    N: int, T: int, gamma: float, c1: float = 1.0, c2: float = 1.0, rho: Optional[float] = None\n",
        ") -> Tuple[float, int, int]:\n",
        "    NT = max(1, N * max(1, T))\n",
        "    K = int(np.ceil(c1 * np.log(NT) / max(1e-12, (1.0 - gamma))))\n",
        "    alpha = np.log(NT) / (max(1e-12, (1.0 - gamma)) * max(1, K))\n",
        "    if rho is None or not (0.0 < rho < 1.0):\n",
        "        L = 1\n",
        "    else:\n",
        "        num = np.log(max(1.0, c2 * (N**1.5) * np.sqrt(max(1, T)) / np.sqrt(max(1e-12, 1.0 - gamma))))\n",
        "        den = np.log(1.0 / rho)\n",
        "        L = int(np.ceil(num / max(1e-12, den)))\n",
        "    return alpha, K, L\n",
        "\n",
        "# ---------- MDP & VRDQ core ----------\n",
        "\n",
        "@dataclass\n",
        "class TabularMDP:\n",
        "    P: np.ndarray  # [S, A, S]\n",
        "    R: np.ndarray  # [S, A]\n",
        "    gamma: float\n",
        "    @property\n",
        "    def S(self) -> int: return self.P.shape[0]\n",
        "    @property\n",
        "    def A(self) -> int: return self.P.shape[1]\n",
        "\n",
        "def random_tabular_mdp(S: int, A: int, gamma: float, rng: np.random.Generator) -> TabularMDP:\n",
        "    P = rng.random((S, A, S))\n",
        "    P /= P.sum(axis=2, keepdims=True)\n",
        "    R = rng.random((S, A))  # rewards in [0,1]\n",
        "    return TabularMDP(P=P, R=R, gamma=gamma)\n",
        "\n",
        "def empirical_transition(N: int, S: int, A: int, H: int, mdp: TabularMDP, rng: np.random.Generator) -> np.ndarray:\n",
        "    P_hat = np.zeros((N, S, A, S), dtype=float)\n",
        "    for i in range(N):\n",
        "        for s in range(S):\n",
        "            for a in range(A):\n",
        "                counts = np.zeros(S, dtype=float)\n",
        "                for _ in range(H):\n",
        "                    ns = rng.choice(S, p=mdp.P[s, a])\n",
        "                    counts[ns] += 1.0\n",
        "                P_hat[i, s, a] = counts / counts.sum() if counts.sum() > 0 else np.ones(S) / S\n",
        "    return P_hat\n",
        "\n",
        "def q_update_pre_diffusion(Q_i: np.ndarray, P_hat_i: np.ndarray, R: np.ndarray, gamma: float, alpha: float) -> np.ndarray:\n",
        "    S, A = Q_i.shape\n",
        "    d0 = np.zeros_like(Q_i)\n",
        "    Q_max = Q_i.max(axis=1)\n",
        "    for s in range(S):\n",
        "        for a in range(A):\n",
        "            v_next = float(P_hat_i[s, a] @ Q_max)\n",
        "            td = R[s, a] + gamma * v_next - Q_i[s, a]\n",
        "            d0[s, a] = alpha * td\n",
        "    return d0\n",
        "\n",
        "def diffuse_deltas_over_agents(d0_stack: np.ndarray, W: np.ndarray, L: int) -> np.ndarray:\n",
        "    if L <= 0: return d0_stack.copy()\n",
        "    WL = np.linalg.matrix_power(W, L)\n",
        "    N, S, A = d0_stack.shape\n",
        "    dL = np.zeros_like(d0_stack)\n",
        "    for s in range(S):\n",
        "        for a in range(A):\n",
        "            dL[:, s, a] = WL @ d0_stack[:, s, a]\n",
        "    return dL\n",
        "\n",
        "def vrdq_train(mdp: TabularMDP, N: int, H: int, K: int, L: int, alpha: float, W: np.ndarray, seed: int = 0) -> Dict[str, np.ndarray]:\n",
        "    rng = np.random.default_rng(seed)\n",
        "    S, A = mdp.S, mdp.A\n",
        "    Q = np.zeros((N, S, A), dtype=float)\n",
        "    Q_hist, Q_agents_hist = [], []  # store average Q and per-agent Q\n",
        "\n",
        "    for _ in range(K):\n",
        "        P_hat = empirical_transition(N, S, A, H, mdp, rng)\n",
        "        d0 = np.zeros((N, S, A), dtype=float)\n",
        "        for i in range(N):\n",
        "            d0[i] = q_update_pre_diffusion(Q[i], P_hat[i], mdp.R, mdp.gamma, alpha)\n",
        "        dL = diffuse_deltas_over_agents(d0, W, L)\n",
        "        Q += dL\n",
        "        Q_agents_hist.append(Q.copy())          # [N,S,A]\n",
        "        Q_hist.append(Q.mean(axis=0))           # [S,A]\n",
        "\n",
        "    return {\n",
        "        \"Q_agents\": Q,                          # [N,S,A]\n",
        "        \"Q_bar\": Q.mean(axis=0),                # [S,A]\n",
        "        \"Q_hist\": np.array(Q_hist),             # [K,S,A]\n",
        "        \"Q_agents_hist\": np.array(Q_agents_hist) # [K,N,S,A]\n",
        "    }\n",
        "\n",
        "# ---------- Optimal Q* & metrics ----------\n",
        "\n",
        "def value_iteration(mdp: TabularMDP, tol: float = 1e-10, max_iter: int = 10000):\n",
        "    S, A, gamma = mdp.S, mdp.A, mdp.gamma\n",
        "    V = np.zeros(S, dtype=float)\n",
        "    for _ in range(max_iter):\n",
        "        Q = np.zeros((S, A), dtype=float)\n",
        "        for s in range(S):\n",
        "            for a in range(A):\n",
        "                Q[s, a] = mdp.R[s, a] + gamma * float(mdp.P[s, a] @ V)\n",
        "        V_new = Q.max(axis=1)\n",
        "        if np.max(np.abs(V_new - V)) < tol:\n",
        "            V = V_new\n",
        "            break\n",
        "        V = V_new\n",
        "    Q_star = np.zeros((S, A), dtype=float)\n",
        "    for s in range(S):\n",
        "        for a in range(A):\n",
        "            Q_star[s, a] = mdp.R[s, a] + gamma * float(mdp.P[s, a] @ V)\n",
        "    return Q_star, V\n",
        "\n",
        "def linf(x): return np.max(np.abs(x))\n",
        "\n",
        "# ---------- Run & plot ----------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    rng = np.random.default_rng(7)\n",
        "\n",
        "    # Common setup\n",
        "    S, A = 10, 5\n",
        "    N = 10\n",
        "    gamma = 0.9\n",
        "    T = 100_000\n",
        "    c1 = 1.0\n",
        "    c2 = 1.0\n",
        "\n",
        "    mdp = random_tabular_mdp(S, A, gamma, rng)\n",
        "    Q_star, _ = value_iteration(mdp)\n",
        "\n",
        "    graphs = {\n",
        "        \"Ring\": adj_ring(N),\n",
        "        \"Complete\": adj_complete(N),\n",
        "        \"Star\": adj_star(N),\n",
        "    }\n",
        "\n",
        "    # Distinct, color-agnostic styles\n",
        "    style = {\n",
        "        \"Ring\":     {\"linestyle\": \"-\",  \"marker\": \"o\", \"linewidth\": 2, \"markersize\": 3,\"color\":\"blue\"},\n",
        "        \"Complete\": {\"linestyle\": \"--\", \"marker\": \"s\", \"linewidth\": 2, \"markersize\": 4,\"color\":\"black\"},\n",
        "        \"Star\":     {\"linestyle\": \":\",  \"marker\": \"^\", \"linewidth\": 2, \"markersize\": 5,\"color\":\"red\"},\n",
        "    }\n",
        "\n",
        "    errors_bar, gaps_consensus, meta = {}, {}, {}\n",
        "\n",
        "    for name, adj in graphs.items():\n",
        "        W = metropolis_mixing_matrix(adj)\n",
        "        rho = spectral_gap_rho(W)\n",
        "        alpha, K, L = compute_alpha_K_L(N=N, T=T, gamma=gamma, c1=c1, c2=c2, rho=rho)\n",
        "        H=int(T/K)\n",
        "        out = vrdq_train(mdp, N=N, H=H, K=K, L=L, alpha=alpha, W=W, seed=123)\n",
        "        Q_hist = out[\"Q_hist\"]                  # [K,S,A]\n",
        "        Q_agents_hist = out[\"Q_agents_hist\"]    # [K,N,S,A]\n",
        "\n",
        "        # (1) Average-Q error (will coincide across graphs)\n",
        "        E_bar = np.array([linf(Q_hist[k] - Q_star) for k in range(Q_hist.shape[0])])\n",
        "        errors_bar[name] = E_bar\n",
        "\n",
        "        # (2) CONSENSUS GAP: max_i ||Q_i - Q_bar||_inf at each epoch\n",
        "        G = np.zeros(Q_hist.shape[0], dtype=float)\n",
        "        for k in range(Q_hist.shape[0]):\n",
        "            Q_bar_k = Q_hist[k]                            # [S,A]\n",
        "            diffs = [linf(Q_agents_hist[k, i] - Q_bar_k) for i in range(N)]\n",
        "            G[k] = max(diffs)\n",
        "        gaps_consensus[name] = G\n",
        "\n",
        "        meta[name] = {\"rho\": rho, \"L\": L, \"K\": K, \"alpha\": alpha}\n",
        "        np.save(f\"vrdq_error_bar_{name}.npy\", E_bar)\n",
        "        np.save(f\"vrdq_consensus_gap_{name}.npy\", G)\n",
        "\n",
        "    np.save(\"vrdq_Qstar.npy\", Q_star)\n",
        "\n",
        "    # Plot 1: Average-Q error (expected to overlap)\n",
        "    plt.figure(figsize=(8.2, 5.3))\n",
        "    for name in [\"Ring\", \"Complete\", \"Star\"]:\n",
        "        E = errors_bar[name]\n",
        "        st = style[name]\n",
        "        markevery = max(1, len(E) // 12)\n",
        "        plt.semilogy(range(1, len(E)+1), E,\n",
        "                     linestyle=st[\"linestyle\"], marker=st[\"marker\"],\n",
        "                     linewidth=st[\"linewidth\"], markersize=st[\"markersize\"],\n",
        "                     markevery=markevery,\n",
        "                     label=f\"{name}\")\n",
        "    plt.xlabel(r'$\\mathbf{K}$', fontsize=40, fontweight='bold')\n",
        "    plt.ylabel(r'$\\mathbf{E_K}$', fontsize=40, fontweight='bold')\n",
        "    plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.5)\n",
        "    plt.legend(title=r'$\\mathbf{Agents}$', fontsize=20, title_fontsize=20, loc='best')\n",
        "    plt.xticks(fontsize=25, fontweight='bold')\n",
        "    plt.yticks(fontsize=25, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"vrdq_error_bar_compare.png\", dpi=220)\n",
        "    plt.show()\n",
        "\n",
        "    # Plot 2: Consensus gap (this separates the graphs)\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    for name in [\"Ring\", \"Complete\", \"Star\"]:\n",
        "        G = gaps_consensus[name]\n",
        "        st = style[name]\n",
        "        markevery = max(1, len(G) // 12)\n",
        "        plt.semilogy(range(1, len(G)+1), G,\n",
        "                     linestyle=st[\"linestyle\"], marker=st[\"marker\"],\n",
        "                     linewidth=st[\"linewidth\"], markersize=st[\"markersize\"],\n",
        "                     markevery=markevery,\n",
        "                     label=f\"{name}\")\n",
        "    plt.xlabel(\"$\\mathbf{L}$\", fontsize=40, fontweight='bold')\n",
        "    plt.ylabel(r\"$\\mathbf{Consensus \\quad Gap}$\", fontsize=25, fontweight='bold')\n",
        "    plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.5)\n",
        "    plt.legend(title=r'$\\mathbf{Connectivity}$', fontsize=20, title_fontsize=20, loc='best')\n",
        "    plt.tight_layout()\n",
        "    plt.xticks(fontsize=25, fontweight='bold')\n",
        "    plt.yticks(fontsize=25, fontweight='bold')\n",
        "    plt.savefig(\"vrdq_consensus_gap_compare.png\", dpi=1200)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Q9KyGTGekKPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VRDQ_compare_three_graphs_with_consensus_const_weight.py\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, Dict, Optional\n",
        "\n",
        "# ---------- Deterministic graphs ----------\n",
        "\n",
        "def adj_ring(N: int) -> np.ndarray:\n",
        "    adj = np.zeros((N, N), dtype=int)\n",
        "    for i in range(N):\n",
        "        adj[i, (i - 1) % N] = 1\n",
        "        adj[i, (i + 1) % N] = 1\n",
        "    return adj\n",
        "\n",
        "def adj_complete(N: int) -> np.ndarray:\n",
        "    return np.ones((N, N), dtype=int) - np.eye(N, dtype=int)\n",
        "\n",
        "def adj_star(N: int) -> np.ndarray:\n",
        "    adj = np.zeros((N, N), dtype=int)\n",
        "    for j in range(1, N):\n",
        "        adj[0, j] = 1\n",
        "        adj[j, 0] = 1\n",
        "    return adj\n",
        "\n",
        "# ---------- Constant-weight mixing: W = I - w L ----------\n",
        "\n",
        "def laplacian_from_adj(adj: np.ndarray) -> np.ndarray:\n",
        "    deg = adj.sum(axis=1)\n",
        "    L = np.diag(deg) - adj\n",
        "    return L\n",
        "\n",
        "def compute_w_safe(adj: np.ndarray) -> float:\n",
        "    # Safe local choice: w = 1 / Δ\n",
        "    deg = adj.sum(axis=1)\n",
        "    Delta = float(deg.max()) if deg.size > 0 else 1.0\n",
        "    return 1.0 / max(1.0, Delta)\n",
        "\n",
        "def compute_w_spectral(L: np.ndarray) -> float:\n",
        "    # Spectral \"near-optimal\" single-step choice: w = 2 / (λ2 + λn)\n",
        "    # λ1=0 <= λ2 <= ... <= λn are Laplacian eigenvalues\n",
        "    # Fallback to safe if spectrum is degenerate\n",
        "    evals = np.linalg.eigvalsh(L)  # symmetric\n",
        "    evals = np.sort(np.real(evals))\n",
        "    if len(evals) < 2:\n",
        "        return 1.0  # degenerate graph\n",
        "    lam2 = float(evals[1])\n",
        "    lamn = float(evals[-1])\n",
        "    denom = lam2 + lamn\n",
        "    if denom <= 1e-12:\n",
        "        return 1.0  # fallback; will be renormalized below if needed\n",
        "    return 2.0 / denom\n",
        "\n",
        "def const_weight_mixing(adj: np.ndarray, mode: str = \"safe\") -> Tuple[np.ndarray, float]:\n",
        "    \"\"\"\n",
        "    Build symmetric, (row-)doubly-stochastic mixing matrix:\n",
        "       W = I - w L\n",
        "    mode: \"safe\" uses w = 1/Δ; \"spectral\" uses w = 2/(λ2+λn).\n",
        "    \"\"\"\n",
        "    n = adj.shape[0]\n",
        "    L = laplacian_from_adj(adj)\n",
        "    if mode == \"spectral\":\n",
        "        w = compute_w_spectral(L)\n",
        "        # Ensure nonnegativity: clip by maximum degree if needed\n",
        "        deg = adj.sum(axis=1)\n",
        "        Delta = float(deg.max()) if deg.size > 0 else 1.0\n",
        "        w = min(w, 1.0 / max(1.0, Delta))\n",
        "    else:\n",
        "        w = compute_w_safe(adj)\n",
        "\n",
        "    W = np.eye(n) - w * L  # symmetric by construction\n",
        "    # Numerical hygiene: clip tiny negatives, renormalize rows to sum 1\n",
        "    W[W < 0] = 0.0\n",
        "    row_sums = W.sum(axis=1, keepdims=True)\n",
        "    row_sums[row_sums == 0] = 1.0\n",
        "    W = W / row_sums\n",
        "    # Re-symmetrize (tiny asymmetries can appear after renorm)\n",
        "    W = 0.5 * (W + W.T)\n",
        "    # Renormalize again to keep rows = 1 exactly\n",
        "    W = W / W.sum(axis=1, keepdims=True)\n",
        "    return W, w\n",
        "\n",
        "def spectral_gap_rho(W: np.ndarray) -> float:\n",
        "    eig = np.linalg.eigvals(W)\n",
        "    eig = np.sort(np.abs(np.real(eig)))[::-1]\n",
        "    return float(eig[1]) if len(eig) > 1 else 0.0  # SLEM (ρ)\n",
        "\n",
        "# ---------- Hyperparameters ----------\n",
        "\n",
        "def compute_alpha_K_L(\n",
        "    N: int, T: int, gamma: float, c1: float = 1.0, c2: float = 1.0, rho: Optional[float] = None\n",
        ") -> Tuple[float, int, int]:\n",
        "    NT = max(1, N * max(1, T))\n",
        "    K = int(np.ceil(c1 * np.log(NT) / max(1e-12, (1.0 - gamma))))\n",
        "    alpha = np.log(NT) / (max(1e-12, (1.0 - gamma)) * max(1, K))\n",
        "    if rho is None or not (0.0 < rho < 1.0):\n",
        "        L = 1\n",
        "    else:\n",
        "        # same heuristic as your original code\n",
        "        num = np.log(max(1.0, c2 * (N**1.5) * np.sqrt(max(1, T)) / np.sqrt(max(1e-12, 1.0 - gamma))))\n",
        "        den = np.log(1.0 / rho)\n",
        "        L = int(np.ceil(num / max(1e-12, den)))\n",
        "    return alpha, K, L\n",
        "\n",
        "# ---------- MDP & VRDQ core ----------\n",
        "\n",
        "@dataclass\n",
        "class TabularMDP:\n",
        "    P: np.ndarray  # [S, A, S]\n",
        "    R: np.ndarray  # [S, A]\n",
        "    gamma: float\n",
        "    @property\n",
        "    def S(self) -> int: return self.P.shape[0]\n",
        "    @property\n",
        "    def A(self) -> int: return self.P.shape[1]\n",
        "\n",
        "def random_tabular_mdp(S: int, A: int, gamma: float, rng: np.random.Generator) -> TabularMDP:\n",
        "    P = rng.random((S, A, S))\n",
        "    P /= P.sum(axis=2, keepdims=True)\n",
        "    R = rng.random((S, A))  # rewards in [0,1]\n",
        "    return TabularMDP(P=P, R=R, gamma=gamma)\n",
        "\n",
        "def empirical_transition(N: int, S: int, A: int, H: int, mdp: TabularMDP, rng: np.random.Generator) -> np.ndarray:\n",
        "    P_hat = np.zeros((N, S, A, S), dtype=float)\n",
        "    for i in range(N):\n",
        "        for s in range(S):\n",
        "            for a in range(A):\n",
        "                counts = np.zeros(S, dtype=float)\n",
        "                for _ in range(H):\n",
        "                    ns = rng.choice(S, p=mdp.P[s, a])\n",
        "                    counts[ns] += 1.0\n",
        "                P_hat[i, s, a] = counts / counts.sum() if counts.sum() > 0 else np.ones(S) / S\n",
        "    return P_hat\n",
        "\n",
        "def q_update_pre_diffusion(Q_i: np.ndarray, P_hat_i: np.ndarray, R: np.ndarray, gamma: float, alpha: float) -> np.ndarray:\n",
        "    S, A = Q_i.shape\n",
        "    d0 = np.zeros_like(Q_i)\n",
        "    Q_max = Q_i.max(axis=1)\n",
        "    for s in range(S):\n",
        "        for a in range(A):\n",
        "            v_next = float(P_hat_i[s, a] @ Q_max)\n",
        "            td = R[s, a] + gamma * v_next - Q_i[s, a]\n",
        "            d0[s, a] = alpha * td\n",
        "    return d0\n",
        "\n",
        "def diffuse_deltas_over_agents(d0_stack: np.ndarray, W: np.ndarray, L: int) -> np.ndarray:\n",
        "    if L <= 0: return d0_stack.copy()\n",
        "    WL = np.linalg.matrix_power(W, L)\n",
        "    N, S, A = d0_stack.shape\n",
        "    dL = np.zeros_like(d0_stack)\n",
        "    for s in range(S):\n",
        "        for a in range(A):\n",
        "            dL[:, s, a] = WL @ d0_stack[:, s, a]\n",
        "    return dL\n",
        "\n",
        "def vrdq_train(mdp: TabularMDP, N: int, H: int, K: int, L: int, alpha: float, W: np.ndarray, seed: int = 0) -> Dict[str, np.ndarray]:\n",
        "    rng = np.random.default_rng(seed)\n",
        "    S, A = mdp.S, mdp.A\n",
        "    Q = np.zeros((N, S, A), dtype=float)\n",
        "    Q_hist, Q_agents_hist = [], []  # store average Q and per-agent Q\n",
        "\n",
        "    for _ in range(K):\n",
        "        P_hat = empirical_transition(N, S, A, H, mdp, rng)\n",
        "        d0 = np.zeros((N, S, A), dtype=float)\n",
        "        for i in range(N):\n",
        "            d0[i] = q_update_pre_diffusion(Q[i], P_hat[i], mdp.R, mdp.gamma, alpha)\n",
        "        dL = diffuse_deltas_over_agents(d0, W, L)\n",
        "        Q += dL\n",
        "        Q_agents_hist.append(Q.copy())          # [N,S,A]\n",
        "        Q_hist.append(Q.mean(axis=0))           # [S,A]\n",
        "\n",
        "    return {\n",
        "        \"Q_agents\": Q,                          # [N,S,A]\n",
        "        \"Q_bar\": Q.mean(axis=0),                # [S,A]\n",
        "        \"Q_hist\": np.array(Q_hist),             # [K,S,A]\n",
        "        \"Q_agents_hist\": np.array(Q_agents_hist) # [K,N,S,A]\n",
        "    }\n",
        "\n",
        "# ---------- Optimal Q* & metrics ----------\n",
        "\n",
        "def value_iteration(mdp: TabularMDP, tol: float = 1e-10, max_iter: int = 10000):\n",
        "    S, A, gamma = mdp.S, mdp.A, mdp.gamma\n",
        "    V = np.zeros(S, dtype=float)\n",
        "    for _ in range(max_iter):\n",
        "        Q = np.zeros((S, A), dtype=float)\n",
        "        for s in range(S):\n",
        "            for a in range(A):\n",
        "                Q[s, a] = mdp.R[s, a] + gamma * float(mdp.P[s, a] @ V)\n",
        "        V_new = Q.max(axis=1)\n",
        "        if np.max(np.abs(V_new - V)) < tol:\n",
        "            V = V_new\n",
        "            break\n",
        "        V = V_new\n",
        "    Q_star = np.zeros((S, A), dtype=float)\n",
        "    for s in range(S):\n",
        "        for a in range(A):\n",
        "            Q_star[s, a] = mdp.R[s, a] + gamma * float(mdp.P[s, a] @ V)\n",
        "    return Q_star, V\n",
        "\n",
        "def linf(x): return np.max(np.abs(x))\n",
        "\n",
        "# ---------- Run & plot ----------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    rng = np.random.default_rng(7)\n",
        "\n",
        "    # Common setup\n",
        "    S, A = 10, 5\n",
        "    N = 10\n",
        "    gamma = 0.9\n",
        "    T = 100_000\n",
        "    c1 = 1.0\n",
        "    c2 = 1.0\n",
        "\n",
        "    mdp = random_tabular_mdp(S, A, gamma, rng)\n",
        "    Q_star, _ = value_iteration(mdp)\n",
        "\n",
        "    graphs = {\n",
        "        \"Ring\": adj_ring(N),\n",
        "        \"Complete\": adj_complete(N),\n",
        "        \"Star\": adj_star(N),\n",
        "    }\n",
        "\n",
        "    # Choose which w to use: \"safe\" (1/Δ) or \"spectral\" (2/(λ2+λn) clipped to 1/Δ)\n",
        "    w_mode = \"spectral\"       # change to \"spectral\" if you want the eigen-based step\n",
        "\n",
        "    # Distinct, color-agnostic styles\n",
        "    style = {\n",
        "        \"Ring\":     {\"linestyle\": \"-\",  \"marker\": \"o\", \"linewidth\": 2, \"markersize\": 3, \"color\": \"blue\"},\n",
        "        \"Complete\": {\"linestyle\": \"--\", \"marker\": \"s\", \"linewidth\": 2, \"markersize\": 4, \"color\": \"black\"},\n",
        "        \"Star\":     {\"linestyle\": \":\",  \"marker\": \"^\", \"linewidth\": 2, \"markersize\": 5, \"color\": \"red\"},\n",
        "    }\n",
        "\n",
        "    errors_bar, gaps_consensus, meta = {}, {}, {}\n",
        "\n",
        "    for name, adj in graphs.items():\n",
        "        W, w = const_weight_mixing(adj, mode=w_mode)\n",
        "        rho = spectral_gap_rho(W)\n",
        "        alpha, K, L = compute_alpha_K_L(N=N, T=T, gamma=gamma, c1=c1, c2=c2, rho=rho)\n",
        "        H=int(T/K)\n",
        "        out = vrdq_train(mdp, N=N, H=H, K=K, L=L, alpha=alpha, W=W, seed=123)\n",
        "        Q_hist = out[\"Q_hist\"]                  # [K,S,A]\n",
        "        Q_agents_hist = out[\"Q_agents_hist\"]    # [K,N,S,A]\n",
        "\n",
        "        # (1) Average-Q error (invariant under doubly-stochastic W)\n",
        "        E_bar = np.array([linf(Q_hist[k] - Q_star) for k in range(Q_hist.shape[0])])\n",
        "        errors_bar[name] = E_bar\n",
        "\n",
        "        # (2) CONSENSUS GAP: max_i ||Q_i - Q_bar||_inf at each epoch\n",
        "        G = np.zeros(Q_hist.shape[0], dtype=float)\n",
        "        for k in range(Q_hist.shape[0]):\n",
        "            Q_bar_k = Q_hist[k]                            # [S,A]\n",
        "            diffs = [linf(Q_agents_hist[k, i] - Q_bar_k) for i in range(N)]\n",
        "            G[k] = max(diffs)\n",
        "        gaps_consensus[name] = G\n",
        "\n",
        "        meta[name] = {\"rho\": rho, \"L\": L, \"K\": K, \"alpha\": alpha, \"w\": w}\n",
        "        np.save(f\"vrdq_error_bar_{name}.npy\", E_bar)\n",
        "        np.save(f\"vrdq_consensus_gap_{name}.npy\", G)\n",
        "\n",
        "    np.save(\"vrdq_Qstar.npy\", Q_star)\n",
        "\n",
        "    # Plot 1: Average-Q error\n",
        "    plt.figure(figsize=(8.2, 5.3))\n",
        "    for name in [\"Ring\", \"Complete\", \"Star\"]:\n",
        "        E = errors_bar[name]\n",
        "        st = style[name]\n",
        "        markevery = max(1, len(E) // 12)\n",
        "        plt.semilogy(range(1, len(E)+1), E,\n",
        "                     linestyle=st[\"linestyle\"], marker=st[\"marker\"],\n",
        "                     linewidth=st[\"linewidth\"], markersize=st[\"markersize\"],\n",
        "                     markevery=markevery,\n",
        "                     label=f\"{name}\")\n",
        "    plt.xlabel(r'$\\mathbf{K}$', fontsize=40, fontweight='bold')\n",
        "    plt.ylabel(r'$\\mathbf{E_K}$', fontsize=40, fontweight='bold')\n",
        "    plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.5)\n",
        "    plt.legend(title=r'$\\mathbf{Connectivity}, N=100$', fontsize=20, title_fontsize=20, loc='best')\n",
        "    plt.xticks(fontsize=25, fontweight='bold')\n",
        "    plt.yticks(fontsize=25, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"vrdq_error_bar_compare.png\", dpi=220)\n",
        "    plt.show()\n",
        "\n",
        "    # Plot 2: Consensus gap (this separates the graphs)\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    for name in [\"Ring\", \"Complete\", \"Star\"]:\n",
        "        G = gaps_consensus[name]\n",
        "        st = style[name]\n",
        "        markevery = max(1, len(G) // 12)\n",
        "        plt.semilogy(range(1, len(G)+1), G,\n",
        "                     linestyle=st[\"linestyle\"], marker=st[\"marker\"],\n",
        "                     linewidth=st[\"linewidth\"], markersize=st[\"markersize\"],\n",
        "                     markevery=markevery,\n",
        "                     label=f\"{name}\")\n",
        "    plt.xlabel(r\"$\\mathbf{L}$\", fontsize=40, fontweight='bold')  # epochs\n",
        "    plt.ylabel(r\"$\\mathbf{Consensus \\; Gap}$\", fontsize=25, fontweight='bold')\n",
        "    plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.5)\n",
        "    plt.legend(title=r'$\\mathbf{Connectivity}$', fontsize=20, title_fontsize=20, loc='best')\n",
        "    plt.tight_layout()\n",
        "    plt.xticks(fontsize=25, fontweight='bold')\n",
        "    plt.yticks(fontsize=25, fontweight='bold')\n",
        "    plt.savefig(\"vrdq_consensus_gap_compare.png\", dpi=1200)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "f3GTtDByvNYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vrdq_compare_three_graphs_with_consensus_const_weight.py\n",
        "# -------------------------------------------------------------\n",
        "# Same experiment, but using the constant-weight Laplacian scheme:\n",
        "#   W = I - w L, with either:\n",
        "#     (i)  w = 1 / Δ                [safe, local]\n",
        "#     (ii) w = 2 / (λ2 + λn)        [spectral, faster if available]\n",
        "# This typically yields a larger spectral gap than Metropolis.\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, Dict, Optional\n",
        "\n",
        "# ---------- Deterministic graphs ----------\n",
        "\n",
        "def adj_ring(N: int) -> np.ndarray:\n",
        "    adj = np.zeros((N, N), dtype=int)\n",
        "    for i in range(N):\n",
        "        adj[i, (i - 1) % N] = 1\n",
        "        adj[i, (i + 1) % N] = 1\n",
        "    return adj\n",
        "\n",
        "def adj_complete(N: int) -> np.ndarray:\n",
        "    return np.ones((N, N), dtype=int) - np.eye(N, dtype=int)\n",
        "\n",
        "def adj_star(N: int) -> np.ndarray:\n",
        "    adj = np.zeros((N, N), dtype=int)\n",
        "    for j in range(1, N):\n",
        "        adj[0, j] = 1\n",
        "        adj[j, 0] = 1\n",
        "    return adj\n",
        "\n",
        "# ---------- Constant-weight mixing: W = I - w L ----------\n",
        "\n",
        "def laplacian_from_adj(adj: np.ndarray) -> np.ndarray:\n",
        "    deg = adj.sum(axis=1)\n",
        "    L = np.diag(deg) - adj\n",
        "    return L\n",
        "\n",
        "def compute_w_safe(adj: np.ndarray) -> float:\n",
        "    # Safe local choice: w = 1 / Δ\n",
        "    deg = adj.sum(axis=1)\n",
        "    Delta = float(deg.max()) if deg.size > 0 else 1.0\n",
        "    return 1.0 / max(1.0, Delta)\n",
        "\n",
        "def compute_w_spectral(L: np.ndarray) -> float:\n",
        "    # Spectral \"near-optimal\" single-step choice: w = 2 / (λ2 + λn)\n",
        "    # λ1=0 <= λ2 <= ... <= λn are Laplacian eigenvalues\n",
        "    # Fallback to safe if spectrum is degenerate\n",
        "    evals = np.linalg.eigvalsh(L)  # symmetric\n",
        "    evals = np.sort(np.real(evals))\n",
        "    if len(evals) < 2:\n",
        "        return 1.0  # degenerate graph\n",
        "    lam2 = float(evals[1])\n",
        "    lamn = float(evals[-1])\n",
        "    denom = lam2 + lamn\n",
        "    if denom <= 1e-12:\n",
        "        return 1.0  # fallback; will be renormalized below if needed\n",
        "    return 2.0 / denom\n",
        "\n",
        "def const_weight_mixing(adj: np.ndarray, mode: str = \"safe\") -> Tuple[np.ndarray, float]:\n",
        "    \"\"\"\n",
        "    Build symmetric, (row-)doubly-stochastic mixing matrix:\n",
        "       W = I - w L\n",
        "    mode: \"safe\" uses w = 1/Δ; \"spectral\" uses w = 2/(λ2+λn).\n",
        "    \"\"\"\n",
        "    n = adj.shape[0]\n",
        "    L = laplacian_from_adj(adj)\n",
        "    if mode == \"spectral\":\n",
        "        w = compute_w_spectral(L)\n",
        "        # Ensure nonnegativity: clip by maximum degree if needed\n",
        "        deg = adj.sum(axis=1)\n",
        "        Delta = float(deg.max()) if deg.size > 0 else 1.0\n",
        "        w = min(w, 1.0 / max(1.0, Delta))\n",
        "    else:\n",
        "        w = compute_w_safe(adj)\n",
        "\n",
        "    W = np.eye(n) - w * L  # symmetric by construction\n",
        "    # Numerical hygiene: clip tiny negatives, renormalize rows to sum 1\n",
        "    W[W < 0] = 0.0\n",
        "    row_sums = W.sum(axis=1, keepdims=True)\n",
        "    row_sums[row_sums == 0] = 1.0\n",
        "    W = W / row_sums\n",
        "    # Re-symmetrize (tiny asymmetries can appear after renorm)\n",
        "    W = 0.5 * (W + W.T)\n",
        "    # Renormalize again to keep rows = 1 exactly\n",
        "    W = W / W.sum(axis=1, keepdims=True)\n",
        "    return W, w\n",
        "\n",
        "def spectral_gap_rho(W: np.ndarray) -> float:\n",
        "    eig = np.linalg.eigvals(W)\n",
        "    eig = np.sort(np.abs(np.real(eig)))[::-1]\n",
        "    return float(eig[1]) if len(eig) > 1 else 0.0  # SLEM (ρ)\n",
        "\n",
        "# ---------- Hyperparameters ----------\n",
        "\n",
        "def compute_alpha_K_L(\n",
        "    N: int, T: int, gamma: float, c1: float = 1.0, c2: float = 1.0, rho: Optional[float] = None\n",
        ") -> Tuple[float, int, int]:\n",
        "    NT = max(1, N * max(1, T))\n",
        "    K = int(np.ceil(c1 * np.log(NT) / max(1e-12, (1.0 - gamma))))\n",
        "    alpha = np.log(NT) / (max(1e-12, (1.0 - gamma)) * max(1, K))\n",
        "    if rho is None or not (0.0 < rho < 1.0):\n",
        "        L = 1\n",
        "    else:\n",
        "        # same heuristic as your original code\n",
        "        num = np.log(max(1.0, c2 * (N**1.5) * np.sqrt(max(1, T)) / np.sqrt(max(1e-12, 1.0 - gamma))))\n",
        "        den = np.log(1.0 / rho)\n",
        "        L = int(np.ceil(num / max(1e-12, den)))\n",
        "    return alpha, K, L\n",
        "\n",
        "# ---------- MDP & VRDQ core ----------\n",
        "\n",
        "@dataclass\n",
        "class TabularMDP:\n",
        "    P: np.ndarray  # [S, A, S]\n",
        "    R: np.ndarray  # [S, A]\n",
        "    gamma: float\n",
        "    @property\n",
        "    def S(self) -> int: return self.P.shape[0]\n",
        "    @property\n",
        "    def A(self) -> int: return self.P.shape[1]\n",
        "\n",
        "def random_tabular_mdp(S: int, A: int, gamma: float, rng: np.random.Generator) -> TabularMDP:\n",
        "    P = rng.random((S, A, S))\n",
        "    P /= P.sum(axis=2, keepdims=True)\n",
        "    R = rng.random((S, A))  # rewards in [0,1]\n",
        "    return TabularMDP(P=P, R=R, gamma=gamma)\n",
        "\n",
        "def empirical_transition(N: int, S: int, A: int, H: int, mdp: TabularMDP, rng: np.random.Generator) -> np.ndarray:\n",
        "    P_hat = np.zeros((N, S, A, S), dtype=float)\n",
        "    for i in range(N):\n",
        "        for s in range(S):\n",
        "            for a in range(A):\n",
        "                counts = np.zeros(S, dtype=float)\n",
        "                for _ in range(H):\n",
        "                    ns = rng.choice(S, p=mdp.P[s, a])\n",
        "                    counts[ns] += 1.0\n",
        "                P_hat[i, s, a] = counts / counts.sum() if counts.sum() > 0 else np.ones(S) / S\n",
        "    return P_hat\n",
        "\n",
        "def q_update_pre_diffusion(Q_i: np.ndarray, P_hat_i: np.ndarray, R: np.ndarray, gamma: float, alpha: float) -> np.ndarray:\n",
        "    S, A = Q_i.shape\n",
        "    d0 = np.zeros_like(Q_i)\n",
        "    Q_max = Q_i.max(axis=1)\n",
        "    for s in range(S):\n",
        "        for a in range(A):\n",
        "            v_next = float(P_hat_i[s, a] @ Q_max)\n",
        "            td = R[s, a] + gamma * v_next - Q_i[s, a]\n",
        "            d0[s, a] = alpha * td\n",
        "    return d0\n",
        "\n",
        "def diffuse_deltas_over_agents(d0_stack: np.ndarray, W: np.ndarray, L: int) -> np.ndarray:\n",
        "    if L <= 0: return d0_stack.copy()\n",
        "    WL = np.linalg.matrix_power(W, L)\n",
        "    N, S, A = d0_stack.shape\n",
        "    dL = np.zeros_like(d0_stack)\n",
        "    for s in range(S):\n",
        "        for a in range(A):\n",
        "            dL[:, s, a] = WL @ d0_stack[:, s, a]\n",
        "    return dL\n",
        "\n",
        "def vrdq_train(mdp: TabularMDP, N: int, H: int, K: int, L: int, alpha: float, W: np.ndarray, seed: int = 0) -> Dict[str, np.ndarray]:\n",
        "    rng = np.random.default_rng(seed)\n",
        "    S, A = mdp.S, mdp.A\n",
        "    Q = np.zeros((N, S, A), dtype=float)\n",
        "    Q_hist, Q_agents_hist = [], []  # store average Q and per-agent Q\n",
        "\n",
        "    for _ in range(K):\n",
        "        P_hat = empirical_transition(N, S, A, H, mdp, rng)\n",
        "        d0 = np.zeros((N, S, A), dtype=float)\n",
        "        for i in range(N):\n",
        "            d0[i] = q_update_pre_diffusion(Q[i], P_hat[i], mdp.R, mdp.gamma, alpha)\n",
        "        dL = diffuse_deltas_over_agents(d0, W, L)\n",
        "        Q += dL\n",
        "        Q_agents_hist.append(Q.copy())          # [N,S,A]\n",
        "        Q_hist.append(Q.mean(axis=0))           # [S,A]\n",
        "\n",
        "    return {\n",
        "        \"Q_agents\": Q,                          # [N,S,A]\n",
        "        \"Q_bar\": Q.mean(axis=0),                # [S,A]\n",
        "        \"Q_hist\": np.array(Q_hist),             # [K,S,A]\n",
        "        \"Q_agents_hist\": np.array(Q_agents_hist) # [K,N,S,A]\n",
        "    }\n",
        "\n",
        "# ---------- Optimal Q* & metrics ----------\n",
        "\n",
        "def value_iteration(mdp: TabularMDP, tol: float = 1e-10, max_iter: int = 10000):\n",
        "    S, A, gamma = mdp.S, mdp.A, mdp.gamma\n",
        "    V = np.zeros(S, dtype=float)\n",
        "    for _ in range(max_iter):\n",
        "        Q = np.zeros((S, A), dtype=float)\n",
        "        for s in range(S):\n",
        "            for a in range(A):\n",
        "                Q[s, a] = mdp.R[s, a] + gamma * float(mdp.P[s, a] @ V)\n",
        "        V_new = Q.max(axis=1)\n",
        "        if np.max(np.abs(V_new - V)) < tol:\n",
        "            V = V_new\n",
        "            break\n",
        "        V = V_new\n",
        "    Q_star = np.zeros((S, A), dtype=float)\n",
        "    for s in range(S):\n",
        "        for a in range(A):\n",
        "            Q_star[s, a] = mdp.R[s, a] + gamma * float(mdp.P[s, a] @ V)\n",
        "    return Q_star, V\n",
        "\n",
        "def linf(x): return np.max(np.abs(x))\n",
        "\n",
        "# ---------- Run & plot ----------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    rng = np.random.default_rng(7)\n",
        "\n",
        "    # Common setup\n",
        "    S, A = 10, 5\n",
        "    N = 50\n",
        "    gamma = 0.9\n",
        "    T = 100_000\n",
        "    c1 = 1.0\n",
        "    c2 = 1.0\n",
        "\n",
        "    mdp = random_tabular_mdp(S, A, gamma, rng)\n",
        "    Q_star, _ = value_iteration(mdp)\n",
        "\n",
        "    graphs = {\n",
        "        \"Complete\": adj_complete(N),\n",
        "        \"Ring\": adj_ring(N),\n",
        "        \"Star\": adj_star(N),\n",
        "    }\n",
        "\n",
        "    # Choose which w to use: \"safe\" (1/Δ) or \"spectral\" (2/(λ2+λn) clipped to 1/Δ)\n",
        "    w_mode = \"spectral\"       # change to \"spectral\" if you want the eigen-based step\n",
        "\n",
        "    # Distinct, color-agnostic styles\n",
        "    style = {\n",
        "\n",
        "        \"Complete\": {\"linestyle\": \"--\", \"marker\": \"s\", \"linewidth\": 3, \"markersize\": 7, \"color\": \"black\"},\n",
        "        \"Star\":     {\"linestyle\": \":\",  \"marker\": \"^\", \"linewidth\": 3, \"markersize\": 7, \"color\": \"red\"},\n",
        "        \"Ring\":     {\"linestyle\": \"-\",  \"marker\": \"o\", \"linewidth\": 3, \"markersize\": 7, \"color\": \"blue\"},\n",
        "    }\n",
        "\n",
        "    errors_bar, gaps_consensus, meta = {}, {}, {}\n",
        "\n",
        "    for name, adj in graphs.items():\n",
        "        W, w = const_weight_mixing(adj, mode=w_mode)\n",
        "        rho = spectral_gap_rho(W)\n",
        "        alpha, K, L = compute_alpha_K_L(N=N, T=T, gamma=gamma, c1=c1, c2=c2, rho=rho)\n",
        "        H=int(T/K)\n",
        "        out = vrdq_train(mdp, N=N, H=H, K=K, L=L, alpha=alpha, W=W, seed=123)\n",
        "        Q_hist = out[\"Q_hist\"]                  # [K,S,A]\n",
        "        Q_agents_hist = out[\"Q_agents_hist\"]    # [K,N,S,A]\n",
        "\n",
        "        # (1) Average-Q error (invariant under doubly-stochastic W)\n",
        "        E_bar = np.array([linf(Q_hist[k] - Q_star) for k in range(Q_hist.shape[0])])\n",
        "        errors_bar[name] = E_bar\n",
        "\n",
        "        # (2) CONSENSUS GAP: max_i ||Q_i - Q_bar||_inf at each epoch\n",
        "        G = np.zeros(Q_hist.shape[0], dtype=float)\n",
        "        for k in range(Q_hist.shape[0]):\n",
        "            Q_bar_k = Q_hist[k]                            # [S,A]\n",
        "            diffs = [linf(Q_agents_hist[k, i] - Q_bar_k) for i in range(N)]\n",
        "            G[k] = max(diffs)\n",
        "        gaps_consensus[name] = G\n",
        "\n",
        "        meta[name] = {\"rho\": rho, \"L\": L, \"K\": K, \"alpha\": alpha, \"w\": w}\n",
        "        np.save(f\"vrdq_error_bar_{name}.npy\", E_bar)\n",
        "        np.save(f\"vrdq_consensus_gap_{name}.npy\", G)\n",
        "\n",
        "    np.save(\"vrdq_Qstar.npy\", Q_star)\n",
        "\n",
        "    # Plot 1: Average-Q error\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for name in [\"Ring\", \"Complete\", \"Star\"]:\n",
        "        E = errors_bar[name]\n",
        "        st = style[name]\n",
        "        markevery = max(1, len(E) // 12)\n",
        "        plt.semilogy(range(1, len(E)+1), E,\n",
        "                     linestyle=st[\"linestyle\"], marker=st[\"marker\"],\n",
        "                     linewidth=st[\"linewidth\"], markersize=st[\"markersize\"],\n",
        "                     markevery=markevery,\n",
        "                     label=f\"{name}\")\n",
        "    plt.xlabel(r'$\\mathbf{K}$', fontsize=40, fontweight='bold')\n",
        "    plt.ylabel(r'$\\mathbf{E_K}$', fontsize=40, fontweight='bold')\n",
        "    plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.5)\n",
        "    plt.legend(title=r'$\\mathbf{Connectivity}$', fontsize=20, title_fontsize=20, loc='best')\n",
        "    plt.xticks(fontsize=25, fontweight='bold')\n",
        "    plt.yticks(fontsize=25, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"vrdq_error_bar_compare.png\", dpi=220)\n",
        "    plt.show()\n",
        "\n",
        "    # Plot 2: Consensus gap (this separates the graphs)\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for name in [\"Ring\", \"Complete\", \"Star\"]:\n",
        "        G = gaps_consensus[name]\n",
        "        st = style[name]\n",
        "        markevery = max(1, len(G) // 12)\n",
        "        plt.semilogy(range(1, len(G)+1), G,\n",
        "                     linestyle=st[\"linestyle\"], marker=st[\"marker\"],\n",
        "                     linewidth=st[\"linewidth\"], markersize=st[\"markersize\"],\n",
        "                     markevery=markevery,\n",
        "                     label=f\"{name}\")\n",
        "    plt.xlim([0,150])\n",
        "    plt.xlabel(r\"$\\mathbf{L}$\", fontsize=40, fontweight='bold')  # epochs\n",
        "    plt.ylabel(r\"$\\mathbf{Consensus \\; Gap}$\", fontsize=25, fontweight='bold')\n",
        "    plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.5)\n",
        "    plt.legend(title=r'$\\mathbf{Connectivity}$', fontsize=20, title_fontsize=20, loc='best')\n",
        "    plt.tight_layout()\n",
        "    plt.xticks(fontsize=25, fontweight='bold')\n",
        "    plt.yticks(fontsize=25, fontweight='bold')\n",
        "    plt.savefig(\"vrdq_consensus_gap_compare.png\", dpi=1200)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "XdmsJ8l8zwY1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}